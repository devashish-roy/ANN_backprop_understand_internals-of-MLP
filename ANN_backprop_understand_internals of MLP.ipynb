{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artificial Neural Network and Backpropagation\n",
    "(Understand internal workings of mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions of non-linear activations\n",
    "def f_sigmoid(X, deriv=False):\n",
    "    if not deriv:\n",
    "        return 1 / (1 + np.exp(-X))\n",
    "    else:\n",
    "        return f_sigmoid(X)*(1 - f_sigmoid(X))\n",
    "\n",
    "\n",
    "def f_softmax(X):\n",
    "    Z = np.sum(np.exp(X), axis=1)\n",
    "    Z = Z.reshape(Z.shape[0], 1)\n",
    "    return np.exp(X) / Z\n",
    "\n",
    "\n",
    "def f_relu(X, deriv=False):\n",
    "    if not deriv:\n",
    "        return np.maximum(0, X)\n",
    "    else:\n",
    "        return np.where(X > 0, 1, 0)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exit_with_err(err_str):\n",
    "    #print >> sys.stderr, err_str\n",
    "    print(err_str, file=sys.stderr)\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functionality of a single hidden layer\n",
    "class Layer:\n",
    "    def __init__(self, size, batch_size, is_input=False, is_output=False,\n",
    "                 activation=f_sigmoid):\n",
    "        self.is_input = is_input\n",
    "        self.is_output = is_output\n",
    "\n",
    "        # Z is the matrix that holds output values\n",
    "        self.Z = np.zeros((batch_size, size[0]))\n",
    "        # The activation function is an externally defined function (with a\n",
    "        # derivative) that is stored here\n",
    "        self.activation = activation\n",
    "\n",
    "        # W is the outgoing weight matrix for this layer\n",
    "        self.W = None\n",
    "        # S is the matrix that holds the inputs to this layer\n",
    "        self.S = None\n",
    "        # D is the matrix that holds the deltas for this layer\n",
    "        self.D = None\n",
    "        # Fp is the matrix that holds the derivatives of the activation function\n",
    "        self.Fp = None\n",
    "\n",
    "        if not is_input:\n",
    "            self.S = np.zeros((batch_size, size[0]))\n",
    "            self.D = np.zeros((batch_size, size[0]))\n",
    "\n",
    "        if not is_output:\n",
    "            self.W = np.random.normal(size=size, scale=1E-4)\n",
    "\n",
    "        if not is_input and not is_output:\n",
    "            self.Fp = np.zeros((size[0], batch_size))\n",
    "\n",
    "    def forward_propagate(self):\n",
    "        if self.is_input:\n",
    "            return self.Z.dot(self.W)\n",
    "\n",
    "        self.Z = self.activation(self.S)\n",
    "        if self.is_output:\n",
    "            return self.Z\n",
    "        else:\n",
    "            # For hidden layers, we add the bias values here\n",
    "            self.Z = np.append(self.Z, np.ones((self.Z.shape[0], 1)), axis=1)\n",
    "            self.Fp = self.activation(self.S, deriv=True).T\n",
    "            return self.Z.dot(self.W)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLayerPerceptron:\n",
    "    def __init__(self, layer_config, batch_size=100, activation_hidden=f_sigmoid ):\n",
    "        self.layers = []\n",
    "        self.num_layers = len(layer_config)\n",
    "        self.minibatch_size = batch_size\n",
    "\n",
    "        for i in range(self.num_layers-1):\n",
    "            if i == 0:\n",
    "                print (\"Initializing input layer with size {0}.\".format(layer_config[i]))\n",
    "                # Here, we add an additional unit at the input for the bias\n",
    "                # weight.\n",
    "                self.layers.append(Layer([layer_config[i]+1, layer_config[i+1]],\n",
    "                                         batch_size,\n",
    "                                         is_input=True))\n",
    "            else:\n",
    "                print (\"Initializing hidden layer with size {0}.\".format(layer_config[i]))\n",
    "                # Here we add an additional unit in the hidden layers for the\n",
    "                # bias weight.\n",
    "                self.layers.append(Layer([layer_config[i]+1, layer_config[i+1]],\n",
    "                                         batch_size,\n",
    "                                         activation=activation_hidden))\n",
    "\n",
    "        print (\"Initializing output layer with size {0}.\".format(layer_config[-1]))\n",
    "        self.layers.append(Layer([layer_config[-1], None],\n",
    "                                 batch_size,\n",
    "                                 is_output=True,\n",
    "                                 activation=f_softmax))\n",
    "        print (\"Done!\")\n",
    "\n",
    "    def forward_propagate(self, data):\n",
    "        # We need to be sure to add bias values to the input\n",
    "        self.layers[0].Z = np.append(data, np.ones((data.shape[0], 1)), axis=1)\n",
    "\n",
    "        for i in range(self.num_layers-1):\n",
    "            self.layers[i+1].S = self.layers[i].forward_propagate()\n",
    "        return self.layers[-1].forward_propagate()\n",
    "\n",
    "    def backpropagate(self, yhat, labels):\n",
    "        \n",
    "        #exit_with_err(\"FIND ME IN THE CODE, What is computed in the next line of code?\\n\")\n",
    "        # Ans: It calculates the error (predicted - truth)\n",
    "\n",
    "        self.layers[-1].D = (yhat - labels).T  #  D is matrix holding deltas. calculate the delta error (predicted - truth) from output and transpose\n",
    "        for i in range(self.num_layers-2, 0, -1):  # For each layer starting from second last layer, going backward layer by layer\n",
    "            # We do not calculate deltas for the bias values\n",
    "            W_nobias = self.layers[i].W[0:-1, :] # Collect all weights except the bias (last in row) for the current layer\n",
    "            \n",
    "            #exit_with_err(\"FIND ME IN THE CODE, What does this 'for' loop do?\\n\")\n",
    "            # Ans: In summary, it propogates error through the network in backward direction\n",
    "            #      For each layer (except the last layer), it calculates the gradient of the loss from next layer with respect to the \n",
    "            #      weights of current layer (excluding the bias) and the derivative of the activation function of current layer. \n",
    "            #      The result from this is then used to update the weights of the network such that loss is minimised.\n",
    "                        \n",
    "            # W_nobias.dot(self.layers[i+1].D) - weigheted sum of error from the next layer\n",
    "            # *  - Dot product which is element wise multiplication\n",
    "            # self.layers[i].Fp - derivative of the activation function of the current layer\n",
    "            self.layers[i].D = W_nobias.dot(self.layers[i+1].D) * self.layers[i].Fp # Updates the delta, \n",
    "                    \n",
    "    def update_weights(self, eta):\n",
    "        # For each layer, except for the output layer\n",
    "        for i in range(0, self.num_layers-1):\n",
    "            # -eta - eta is learning rate that determines by what factor the weights should be updated.. \n",
    "            #        Negative sign denotes that we move in negative direction that reduces the error\n",
    "            # self.layers[i+1].D - Error of the next layer that was calculated during the back propogation\n",
    "            # self.layers[i].Z - ouput of the current layer that is after applying the activation function (during forward pass). \n",
    "            #                    its also the input to the next layer\n",
    "            # Dot product of error from next layer and output of current layer factored by learnng rate (-eta) gives us weight gradients of the current layer\n",
    "            \n",
    "            W_grad = -eta*(self.layers[i+1].D.dot(self.layers[i].Z)).T\n",
    "            self.layers[i].W += W_grad\n",
    "            #print(f'Layer : {i}, Gradients : {W_grad}')\n",
    "\n",
    "    def evaluate(self, train_data, train_labels, test_data, test_labels,\n",
    "                 num_epochs=70, eta=0.05, eval_train=False, eval_test=True):\n",
    "\n",
    "        N_train = len(train_labels)*len(train_labels[0])\n",
    "        N_test = len(test_labels)*len(test_labels[0])\n",
    "\n",
    "        print (\"Training for {0} epochs...\".format(num_epochs))\n",
    "        for t in range(0, num_epochs):\n",
    "            out_str = \"[{0:4d}] \".format(t)\n",
    "\n",
    "            for b_data, b_labels in zip(train_data, train_labels):\n",
    "                output = self.forward_propagate(b_data)\n",
    "                self.backpropagate(output, b_labels)\n",
    "                \n",
    "                #exit_with_err(\"FIND ME IN THE CODE, How does weight update is implemented? What is eta?\\n\")\n",
    "                # Ans: Detailed answer in update_weights fuction \n",
    "                \n",
    "                # Dot product of error from next layer and output of current layer factored by learnng rate (-eta) \n",
    "                # gives us weight gradients of the current layer                \n",
    "                self.update_weights(eta=eta) #eta is defaulted to 0.05\n",
    "\n",
    "            if eval_train:\n",
    "                errs = 0\n",
    "                corrects = 0\n",
    "                for b_data, b_labels in zip(train_data, train_labels):\n",
    "                    output = self.forward_propagate(b_data)\n",
    "                    yhat = np.argmax(output, axis=1)\n",
    "                    errs += np.sum(1-b_labels[np.arange(len(b_labels)), yhat])\n",
    "                    corrects += np.sum(b_labels[np.arange(len(b_labels)), yhat])\n",
    "\n",
    "                out_str = (\"{0} Training error: {1:.5f} Training accuracy: {2:.2f}\".format(out_str,\n",
    "                                                           float(errs)/N_train, float(corrects)/N_train*100))\n",
    "\n",
    "            if eval_test:\n",
    "                errs = 0\n",
    "                corrects = 0\n",
    "                for b_data, b_labels in zip(test_data, test_labels):\n",
    "                    output = self.forward_propagate(b_data)\n",
    "                    yhat = np.argmax(output, axis=1)\n",
    "                    errs += np.sum(1-b_labels[np.arange(len(b_labels)), yhat])\n",
    "                    corrects += np.sum(b_labels[np.arange(len(b_labels)), yhat])\n",
    "\n",
    "                out_str = (\"{0} Test error: {1:.5f}  Test accuracy: {2:.2f}\").format(out_str,\n",
    "                                                       float(errs)/N_test, float(corrects)/N_test*100)\n",
    "\n",
    "            print (out_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_to_bit_vector(labels, nbits):\n",
    "    bit_vector = np.zeros((labels.shape[0], nbits))\n",
    "    for i in range(labels.shape[0]):\n",
    "        bit_vector[i, labels[i]] = 1.0\n",
    "\n",
    "    return bit_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batches(data, labels, batch_size, create_bit_vector=False):\n",
    "    N = data.shape[0]\n",
    "    print (\"Batch size {0}, the number of examples {1}.\".format(batch_size,N))\n",
    "\n",
    "    if N % batch_size != 0:\n",
    "        print (\"Warning in create_minibatches(): Batch size {0} does not \" \\\n",
    "              \"evenly divide the number of examples {1}.\".format(batch_size,N))\n",
    "    chunked_data = []\n",
    "    chunked_labels = []\n",
    "    idx = 0\n",
    "    while idx + batch_size <= N:\n",
    "        chunked_data.append(data[idx:idx+batch_size, :])\n",
    "        if not create_bit_vector:\n",
    "            chunked_labels.append(labels[idx:idx+batch_size])\n",
    "        else:\n",
    "            bit_vector = label_to_bit_vector(labels[idx:idx+batch_size], 10)\n",
    "            chunked_labels.append(bit_vector)\n",
    "\n",
    "        idx += batch_size\n",
    "\n",
    "    return chunked_data, chunked_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_backprop(batch_size, Train_images, Train_labels, Valid_images, Valid_labels):\n",
    "    \n",
    "    print (\"Creating data...\")\n",
    "    batched_train_data, batched_train_labels = create_batches(Train_images, Train_labels,\n",
    "                                              batch_size,\n",
    "                                              create_bit_vector=True)\n",
    "    batched_valid_data, batched_valid_labels = create_batches(Valid_images, Valid_labels,\n",
    "                                              batch_size,\n",
    "                                              create_bit_vector=True)\n",
    "    print (\"Done!\")\n",
    "\n",
    "\n",
    "    return batched_train_data, batched_train_labels,  batched_valid_data, batched_valid_labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "(Xtr, Ltr), (X_test, L_test)=mnist.load_data()\n",
    "\n",
    "Xtr = Xtr.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "Xtr = Xtr.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "Xtr /= 255\n",
    "X_test /= 255\n",
    "print(Xtr.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with suggested configuration of the hyperparameters: number of epochs = 70 and learning rate =0.05\n",
    "- Results at last epoch - Training error: 0.00000, Training accuracy: 100.00, Test error: 0.02570,  Test accuracy: 97.43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating data...\n",
      "Batch size 100, the number of examples 60000.\n",
      "Batch size 100, the number of examples 10000.\n",
      "Done!\n",
      "Initializing input layer with size 784.\n",
      "Initializing hidden layer with size 100.\n",
      "Initializing hidden layer with size 100.\n",
      "Initializing output layer with size 10.\n",
      "Done!\n",
      "Training for 70 epochs...\n",
      "[   0]  Training error: 0.40842 Training accuracy: 59.16 Test error: 0.40290  Test accuracy: 59.71\n",
      "[   1]  Training error: 0.07910 Training accuracy: 92.09 Test error: 0.07720  Test accuracy: 92.28\n",
      "[   2]  Training error: 0.04832 Training accuracy: 95.17 Test error: 0.05200  Test accuracy: 94.80\n",
      "[   3]  Training error: 0.04117 Training accuracy: 95.88 Test error: 0.04750  Test accuracy: 95.25\n",
      "[   4]  Training error: 0.03438 Training accuracy: 96.56 Test error: 0.04190  Test accuracy: 95.81\n",
      "[   5]  Training error: 0.02998 Training accuracy: 97.00 Test error: 0.03800  Test accuracy: 96.20\n",
      "[   6]  Training error: 0.02935 Training accuracy: 97.06 Test error: 0.04110  Test accuracy: 95.89\n",
      "[   7]  Training error: 0.02367 Training accuracy: 97.63 Test error: 0.03620  Test accuracy: 96.38\n",
      "[   8]  Training error: 0.02613 Training accuracy: 97.39 Test error: 0.03950  Test accuracy: 96.05\n",
      "[   9]  Training error: 0.02362 Training accuracy: 97.64 Test error: 0.03690  Test accuracy: 96.31\n",
      "[  10]  Training error: 0.02065 Training accuracy: 97.94 Test error: 0.03620  Test accuracy: 96.38\n",
      "[  11]  Training error: 0.01660 Training accuracy: 98.34 Test error: 0.03320  Test accuracy: 96.68\n",
      "[  12]  Training error: 0.01712 Training accuracy: 98.29 Test error: 0.03450  Test accuracy: 96.55\n",
      "[  13]  Training error: 0.01720 Training accuracy: 98.28 Test error: 0.03580  Test accuracy: 96.42\n",
      "[  14]  Training error: 0.01783 Training accuracy: 98.22 Test error: 0.03530  Test accuracy: 96.47\n",
      "[  15]  Training error: 0.01572 Training accuracy: 98.43 Test error: 0.03410  Test accuracy: 96.59\n",
      "[  16]  Training error: 0.01165 Training accuracy: 98.83 Test error: 0.03060  Test accuracy: 96.94\n",
      "[  17]  Training error: 0.01388 Training accuracy: 98.61 Test error: 0.03290  Test accuracy: 96.71\n",
      "[  18]  Training error: 0.01747 Training accuracy: 98.25 Test error: 0.03550  Test accuracy: 96.45\n",
      "[  19]  Training error: 0.01195 Training accuracy: 98.80 Test error: 0.03190  Test accuracy: 96.81\n",
      "[  20]  Training error: 0.01017 Training accuracy: 98.98 Test error: 0.03120  Test accuracy: 96.88\n",
      "[  21]  Training error: 0.01655 Training accuracy: 98.34 Test error: 0.03680  Test accuracy: 96.32\n",
      "[  22]  Training error: 0.00742 Training accuracy: 99.26 Test error: 0.02940  Test accuracy: 97.06\n",
      "[  23]  Training error: 0.01100 Training accuracy: 98.90 Test error: 0.03220  Test accuracy: 96.78\n",
      "[  24]  Training error: 0.00953 Training accuracy: 99.05 Test error: 0.02940  Test accuracy: 97.06\n",
      "[  25]  Training error: 0.00617 Training accuracy: 99.38 Test error: 0.02890  Test accuracy: 97.11\n",
      "[  26]  Training error: 0.00660 Training accuracy: 99.34 Test error: 0.02950  Test accuracy: 97.05\n",
      "[  27]  Training error: 0.00722 Training accuracy: 99.28 Test error: 0.03010  Test accuracy: 96.99\n",
      "[  28]  Training error: 0.00810 Training accuracy: 99.19 Test error: 0.03210  Test accuracy: 96.79\n",
      "[  29]  Training error: 0.00493 Training accuracy: 99.51 Test error: 0.02760  Test accuracy: 97.24\n",
      "[  30]  Training error: 0.00383 Training accuracy: 99.62 Test error: 0.02800  Test accuracy: 97.20\n",
      "[  31]  Training error: 0.00292 Training accuracy: 99.71 Test error: 0.02840  Test accuracy: 97.16\n",
      "[  32]  Training error: 0.00185 Training accuracy: 99.81 Test error: 0.02640  Test accuracy: 97.36\n",
      "[  33]  Training error: 0.00668 Training accuracy: 99.33 Test error: 0.03010  Test accuracy: 96.99\n",
      "[  34]  Training error: 0.00855 Training accuracy: 99.15 Test error: 0.03270  Test accuracy: 96.73\n",
      "[  35]  Training error: 0.00557 Training accuracy: 99.44 Test error: 0.03070  Test accuracy: 96.93\n",
      "[  36]  Training error: 0.00652 Training accuracy: 99.35 Test error: 0.02950  Test accuracy: 97.05\n",
      "[  37]  Training error: 0.00413 Training accuracy: 99.59 Test error: 0.02930  Test accuracy: 97.07\n",
      "[  38]  Training error: 0.00390 Training accuracy: 99.61 Test error: 0.02830  Test accuracy: 97.17\n",
      "[  39]  Training error: 0.00552 Training accuracy: 99.45 Test error: 0.02820  Test accuracy: 97.18\n",
      "[  40]  Training error: 0.00183 Training accuracy: 99.82 Test error: 0.02620  Test accuracy: 97.38\n",
      "[  41]  Training error: 0.00143 Training accuracy: 99.86 Test error: 0.02820  Test accuracy: 97.18\n",
      "[  42]  Training error: 0.00168 Training accuracy: 99.83 Test error: 0.02820  Test accuracy: 97.18\n",
      "[  43]  Training error: 0.00048 Training accuracy: 99.95 Test error: 0.02700  Test accuracy: 97.30\n",
      "[  44]  Training error: 0.00012 Training accuracy: 99.99 Test error: 0.02620  Test accuracy: 97.38\n",
      "[  45]  Training error: 0.00007 Training accuracy: 99.99 Test error: 0.02590  Test accuracy: 97.41\n",
      "[  46]  Training error: 0.00005 Training accuracy: 100.00 Test error: 0.02610  Test accuracy: 97.39\n",
      "[  47]  Training error: 0.00003 Training accuracy: 100.00 Test error: 0.02600  Test accuracy: 97.40\n",
      "[  48]  Training error: 0.00003 Training accuracy: 100.00 Test error: 0.02610  Test accuracy: 97.39\n",
      "[  49]  Training error: 0.00003 Training accuracy: 100.00 Test error: 0.02600  Test accuracy: 97.40\n",
      "[  50]  Training error: 0.00002 Training accuracy: 100.00 Test error: 0.02630  Test accuracy: 97.37\n",
      "[  51]  Training error: 0.00002 Training accuracy: 100.00 Test error: 0.02620  Test accuracy: 97.38\n",
      "[  52]  Training error: 0.00002 Training accuracy: 100.00 Test error: 0.02620  Test accuracy: 97.38\n",
      "[  53]  Training error: 0.00000 Training accuracy: 100.00 Test error: 0.02620  Test accuracy: 97.38\n",
      "[  54]  Training error: 0.00000 Training accuracy: 100.00 Test error: 0.02600  Test accuracy: 97.40\n",
      "[  55]  Training error: 0.00000 Training accuracy: 100.00 Test error: 0.02610  Test accuracy: 97.39\n",
      "[  56]  Training error: 0.00000 Training accuracy: 100.00 Test error: 0.02600  Test accuracy: 97.40\n",
      "[  57]  Training error: 0.00000 Training accuracy: 100.00 Test error: 0.02600  Test accuracy: 97.40\n",
      "[  58]  Training error: 0.00000 Training accuracy: 100.00 Test error: 0.02600  Test accuracy: 97.40\n",
      "[  59]  Training error: 0.00000 Training accuracy: 100.00 Test error: 0.02600  Test accuracy: 97.40\n",
      "[  60]  Training error: 0.00000 Training accuracy: 100.00 Test error: 0.02600  Test accuracy: 97.40\n",
      "[  61]  Training error: 0.00000 Training accuracy: 100.00 Test error: 0.02600  Test accuracy: 97.40\n",
      "[  62]  Training error: 0.00000 Training accuracy: 100.00 Test error: 0.02580  Test accuracy: 97.42\n",
      "[  63]  Training error: 0.00000 Training accuracy: 100.00 Test error: 0.02570  Test accuracy: 97.43\n",
      "[  64]  Training error: 0.00000 Training accuracy: 100.00 Test error: 0.02560  Test accuracy: 97.44\n",
      "[  65]  Training error: 0.00000 Training accuracy: 100.00 Test error: 0.02580  Test accuracy: 97.42\n",
      "[  66]  Training error: 0.00000 Training accuracy: 100.00 Test error: 0.02580  Test accuracy: 97.42\n",
      "[  67]  Training error: 0.00000 Training accuracy: 100.00 Test error: 0.02570  Test accuracy: 97.43\n",
      "[  68]  Training error: 0.00000 Training accuracy: 100.00 Test error: 0.02570  Test accuracy: 97.43\n",
      "[  69]  Training error: 0.00000 Training accuracy: 100.00 Test error: 0.02570  Test accuracy: 97.43\n",
      "Done:)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size=100;\n",
    "\n",
    "train_data, train_labels, valid_data, valid_labels=prepare_for_backprop(batch_size, Xtr, Ltr, X_test, L_test)\n",
    "\n",
    "mlp = MultiLayerPerceptron(layer_config=[784, 100, 100, 10], batch_size=batch_size)\n",
    "\n",
    "mlp.evaluate(train_data, train_labels, valid_data, valid_labels,\n",
    "             eval_train=True)\n",
    "\n",
    "print(\"Done:)\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training number of epochs = 70 and learning rate =0.005\n",
    "- Results at last epoch - Training error: 0.00055 Training accuracy: 99.94 Test error: 0.02440  Test accuracy: 97.56\n",
    "- Bit slow learning. Error would further reduce with more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating data...\n",
      "Batch size 100, the number of examples 60000.\n",
      "Batch size 100, the number of examples 10000.\n",
      "Done!\n",
      "Initializing input layer with size 784.\n",
      "Initializing hidden layer with size 100.\n",
      "Initializing hidden layer with size 100.\n",
      "Initializing output layer with size 10.\n",
      "Done!\n",
      "Training for 70 epochs...\n",
      "[   0]  Training error: 0.70337 Training accuracy: 29.66 Test error: 0.70060  Test accuracy: 29.94\n",
      "[   1]  Training error: 0.64692 Training accuracy: 35.31 Test error: 0.64320  Test accuracy: 35.68\n",
      "[   2]  Training error: 0.59950 Training accuracy: 40.05 Test error: 0.59810  Test accuracy: 40.19\n",
      "[   3]  Training error: 0.45178 Training accuracy: 54.82 Test error: 0.46030  Test accuracy: 53.97\n",
      "[   4]  Training error: 0.20880 Training accuracy: 79.12 Test error: 0.20030  Test accuracy: 79.97\n",
      "[   5]  Training error: 0.10963 Training accuracy: 89.04 Test error: 0.10770  Test accuracy: 89.23\n",
      "[   6]  Training error: 0.08838 Training accuracy: 91.16 Test error: 0.08670  Test accuracy: 91.33\n",
      "[   7]  Training error: 0.07412 Training accuracy: 92.59 Test error: 0.07390  Test accuracy: 92.61\n",
      "[   8]  Training error: 0.06237 Training accuracy: 93.76 Test error: 0.06320  Test accuracy: 93.68\n",
      "[   9]  Training error: 0.05378 Training accuracy: 94.62 Test error: 0.05620  Test accuracy: 94.38\n",
      "[  10]  Training error: 0.04745 Training accuracy: 95.25 Test error: 0.04940  Test accuracy: 95.06\n",
      "[  11]  Training error: 0.04242 Training accuracy: 95.76 Test error: 0.04550  Test accuracy: 95.45\n",
      "[  12]  Training error: 0.03837 Training accuracy: 96.16 Test error: 0.04220  Test accuracy: 95.78\n",
      "[  13]  Training error: 0.03440 Training accuracy: 96.56 Test error: 0.03940  Test accuracy: 96.06\n",
      "[  14]  Training error: 0.03123 Training accuracy: 96.88 Test error: 0.03620  Test accuracy: 96.38\n",
      "[  15]  Training error: 0.02807 Training accuracy: 97.19 Test error: 0.03480  Test accuracy: 96.52\n",
      "[  16]  Training error: 0.02615 Training accuracy: 97.39 Test error: 0.03320  Test accuracy: 96.68\n",
      "[  17]  Training error: 0.02453 Training accuracy: 97.55 Test error: 0.03210  Test accuracy: 96.79\n",
      "[  18]  Training error: 0.02318 Training accuracy: 97.68 Test error: 0.03170  Test accuracy: 96.83\n",
      "[  19]  Training error: 0.02213 Training accuracy: 97.79 Test error: 0.03090  Test accuracy: 96.91\n",
      "[  20]  Training error: 0.02108 Training accuracy: 97.89 Test error: 0.03080  Test accuracy: 96.92\n",
      "[  21]  Training error: 0.02043 Training accuracy: 97.96 Test error: 0.03080  Test accuracy: 96.92\n",
      "[  22]  Training error: 0.01943 Training accuracy: 98.06 Test error: 0.03010  Test accuracy: 96.99\n",
      "[  23]  Training error: 0.01860 Training accuracy: 98.14 Test error: 0.03020  Test accuracy: 96.98\n",
      "[  24]  Training error: 0.01783 Training accuracy: 98.22 Test error: 0.03030  Test accuracy: 96.97\n",
      "[  25]  Training error: 0.01708 Training accuracy: 98.29 Test error: 0.02980  Test accuracy: 97.02\n",
      "[  26]  Training error: 0.01600 Training accuracy: 98.40 Test error: 0.02930  Test accuracy: 97.07\n",
      "[  27]  Training error: 0.01505 Training accuracy: 98.50 Test error: 0.02880  Test accuracy: 97.12\n",
      "[  28]  Training error: 0.01432 Training accuracy: 98.57 Test error: 0.02820  Test accuracy: 97.18\n",
      "[  29]  Training error: 0.01335 Training accuracy: 98.67 Test error: 0.02780  Test accuracy: 97.22\n",
      "[  30]  Training error: 0.01208 Training accuracy: 98.79 Test error: 0.02730  Test accuracy: 97.27\n",
      "[  31]  Training error: 0.01115 Training accuracy: 98.89 Test error: 0.02670  Test accuracy: 97.33\n",
      "[  32]  Training error: 0.01027 Training accuracy: 98.97 Test error: 0.02620  Test accuracy: 97.38\n",
      "[  33]  Training error: 0.00952 Training accuracy: 99.05 Test error: 0.02620  Test accuracy: 97.38\n",
      "[  34]  Training error: 0.00893 Training accuracy: 99.11 Test error: 0.02640  Test accuracy: 97.36\n",
      "[  35]  Training error: 0.00842 Training accuracy: 99.16 Test error: 0.02620  Test accuracy: 97.38\n",
      "[  36]  Training error: 0.00792 Training accuracy: 99.21 Test error: 0.02580  Test accuracy: 97.42\n",
      "[  37]  Training error: 0.00725 Training accuracy: 99.28 Test error: 0.02580  Test accuracy: 97.42\n",
      "[  38]  Training error: 0.00678 Training accuracy: 99.32 Test error: 0.02570  Test accuracy: 97.43\n",
      "[  39]  Training error: 0.00635 Training accuracy: 99.37 Test error: 0.02540  Test accuracy: 97.46\n",
      "[  40]  Training error: 0.00597 Training accuracy: 99.40 Test error: 0.02590  Test accuracy: 97.41\n",
      "[  41]  Training error: 0.00562 Training accuracy: 99.44 Test error: 0.02550  Test accuracy: 97.45\n",
      "[  42]  Training error: 0.00512 Training accuracy: 99.49 Test error: 0.02530  Test accuracy: 97.47\n",
      "[  43]  Training error: 0.00490 Training accuracy: 99.51 Test error: 0.02570  Test accuracy: 97.43\n",
      "[  44]  Training error: 0.00453 Training accuracy: 99.55 Test error: 0.02580  Test accuracy: 97.42\n",
      "[  45]  Training error: 0.00428 Training accuracy: 99.57 Test error: 0.02560  Test accuracy: 97.44\n",
      "[  46]  Training error: 0.00397 Training accuracy: 99.60 Test error: 0.02530  Test accuracy: 97.47\n",
      "[  47]  Training error: 0.00368 Training accuracy: 99.63 Test error: 0.02550  Test accuracy: 97.45\n",
      "[  48]  Training error: 0.00342 Training accuracy: 99.66 Test error: 0.02580  Test accuracy: 97.42\n",
      "[  49]  Training error: 0.00305 Training accuracy: 99.69 Test error: 0.02590  Test accuracy: 97.41\n",
      "[  50]  Training error: 0.00275 Training accuracy: 99.72 Test error: 0.02570  Test accuracy: 97.43\n",
      "[  51]  Training error: 0.00258 Training accuracy: 99.74 Test error: 0.02580  Test accuracy: 97.42\n",
      "[  52]  Training error: 0.00230 Training accuracy: 99.77 Test error: 0.02520  Test accuracy: 97.48\n",
      "[  53]  Training error: 0.00202 Training accuracy: 99.80 Test error: 0.02510  Test accuracy: 97.49\n",
      "[  54]  Training error: 0.00188 Training accuracy: 99.81 Test error: 0.02480  Test accuracy: 97.52\n",
      "[  55]  Training error: 0.00175 Training accuracy: 99.83 Test error: 0.02520  Test accuracy: 97.48\n",
      "[  56]  Training error: 0.00163 Training accuracy: 99.84 Test error: 0.02470  Test accuracy: 97.53\n",
      "[  57]  Training error: 0.00148 Training accuracy: 99.85 Test error: 0.02460  Test accuracy: 97.54\n",
      "[  58]  Training error: 0.00142 Training accuracy: 99.86 Test error: 0.02470  Test accuracy: 97.53\n",
      "[  59]  Training error: 0.00132 Training accuracy: 99.87 Test error: 0.02490  Test accuracy: 97.51\n",
      "[  60]  Training error: 0.00127 Training accuracy: 99.87 Test error: 0.02470  Test accuracy: 97.53\n",
      "[  61]  Training error: 0.00112 Training accuracy: 99.89 Test error: 0.02480  Test accuracy: 97.52\n",
      "[  62]  Training error: 0.00102 Training accuracy: 99.90 Test error: 0.02470  Test accuracy: 97.53\n",
      "[  63]  Training error: 0.00092 Training accuracy: 99.91 Test error: 0.02490  Test accuracy: 97.51\n",
      "[  64]  Training error: 0.00087 Training accuracy: 99.91 Test error: 0.02520  Test accuracy: 97.48\n",
      "[  65]  Training error: 0.00080 Training accuracy: 99.92 Test error: 0.02500  Test accuracy: 97.50\n",
      "[  66]  Training error: 0.00073 Training accuracy: 99.93 Test error: 0.02500  Test accuracy: 97.50\n",
      "[  67]  Training error: 0.00068 Training accuracy: 99.93 Test error: 0.02470  Test accuracy: 97.53\n",
      "[  68]  Training error: 0.00065 Training accuracy: 99.94 Test error: 0.02470  Test accuracy: 97.53\n",
      "[  69]  Training error: 0.00055 Training accuracy: 99.94 Test error: 0.02440  Test accuracy: 97.56\n",
      "Done:)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size=100;\n",
    "\n",
    "train_data, train_labels, valid_data, valid_labels=prepare_for_backprop(batch_size, Xtr, Ltr, X_test, L_test)\n",
    "\n",
    "mlp = MultiLayerPerceptron(layer_config=[784, 100, 100, 10], batch_size=batch_size)\n",
    "\n",
    "mlp.evaluate(train_data, train_labels, valid_data, valid_labels,\n",
    "             eval_train=True,eta=0.005)\n",
    "\n",
    "print(\"Done:)\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training number of epochs = 70 and learning rate =0.5\n",
    "- Results at last epoch - Training error: 0.90248 Training accuracy: 9.75 Test error: 0.90260  Test accuracy: 9.74\n",
    "- Since 0.5 is high LR, weights are updated at larger rate so model fails to find the optimal weights. Thus model doesnot converge. Instead loss and accuracy keeps fluctuating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating data...\n",
      "Batch size 100, the number of examples 60000.\n",
      "Batch size 100, the number of examples 10000.\n",
      "Done!\n",
      "Initializing input layer with size 784.\n",
      "Initializing hidden layer with size 100.\n",
      "Initializing hidden layer with size 100.\n",
      "Initializing output layer with size 10.\n",
      "Done!\n",
      "Training for 70 epochs...\n",
      "[   0]  Training error: 0.88763 Training accuracy: 11.24 Test error: 0.88650  Test accuracy: 11.35\n",
      "[   1]  Training error: 0.89558 Training accuracy: 10.44 Test error: 0.89720  Test accuracy: 10.28\n",
      "[   2]  Training error: 0.90248 Training accuracy: 9.75 Test error: 0.90260  Test accuracy: 9.74\n",
      "[   3]  Training error: 0.90085 Training accuracy: 9.92 Test error: 0.89910  Test accuracy: 10.09\n",
      "[   4]  Training error: 0.90965 Training accuracy: 9.04 Test error: 0.91080  Test accuracy: 8.92\n",
      "[   5]  Training error: 0.89782 Training accuracy: 10.22 Test error: 0.89900  Test accuracy: 10.10\n",
      "[   6]  Training error: 0.90263 Training accuracy: 9.74 Test error: 0.90180  Test accuracy: 9.82\n",
      "[   7]  Training error: 0.89782 Training accuracy: 10.22 Test error: 0.89900  Test accuracy: 10.10\n",
      "[   8]  Training error: 0.90248 Training accuracy: 9.75 Test error: 0.90260  Test accuracy: 9.74\n",
      "[   9]  Training error: 0.90128 Training accuracy: 9.87 Test error: 0.90200  Test accuracy: 9.80\n",
      "[  10]  Training error: 0.89782 Training accuracy: 10.22 Test error: 0.89900  Test accuracy: 10.10\n",
      "[  11]  Training error: 0.90070 Training accuracy: 9.93 Test error: 0.89680  Test accuracy: 10.32\n",
      "[  12]  Training error: 0.88763 Training accuracy: 11.24 Test error: 0.88650  Test accuracy: 11.35\n",
      "[  13]  Training error: 0.90137 Training accuracy: 9.86 Test error: 0.90420  Test accuracy: 9.58\n",
      "[  14]  Training error: 0.90070 Training accuracy: 9.93 Test error: 0.89680  Test accuracy: 10.32\n",
      "[  15]  Training error: 0.90248 Training accuracy: 9.75 Test error: 0.90260  Test accuracy: 9.74\n",
      "[  16]  Training error: 0.90085 Training accuracy: 9.92 Test error: 0.89910  Test accuracy: 10.09\n",
      "[  17]  Training error: 0.90128 Training accuracy: 9.87 Test error: 0.90200  Test accuracy: 9.80\n",
      "[  18]  Training error: 0.90263 Training accuracy: 9.74 Test error: 0.90180  Test accuracy: 9.82\n",
      "[  19]  Training error: 0.90128 Training accuracy: 9.87 Test error: 0.90200  Test accuracy: 9.80\n",
      "[  20]  Training error: 0.90248 Training accuracy: 9.75 Test error: 0.90260  Test accuracy: 9.74\n",
      "[  21]  Training error: 0.90128 Training accuracy: 9.87 Test error: 0.90200  Test accuracy: 9.80\n",
      "[  22]  Training error: 0.88763 Training accuracy: 11.24 Test error: 0.88650  Test accuracy: 11.35\n",
      "[  23]  Training error: 0.90085 Training accuracy: 9.92 Test error: 0.89910  Test accuracy: 10.09\n",
      "[  24]  Training error: 0.90137 Training accuracy: 9.86 Test error: 0.90420  Test accuracy: 9.58\n",
      "[  25]  Training error: 0.90248 Training accuracy: 9.75 Test error: 0.90260  Test accuracy: 9.74\n",
      "[  26]  Training error: 0.90248 Training accuracy: 9.75 Test error: 0.90260  Test accuracy: 9.74\n",
      "[  27]  Training error: 0.89558 Training accuracy: 10.44 Test error: 0.89720  Test accuracy: 10.28\n",
      "[  28]  Training error: 0.90248 Training accuracy: 9.75 Test error: 0.90260  Test accuracy: 9.74\n",
      "[  29]  Training error: 0.90085 Training accuracy: 9.92 Test error: 0.89910  Test accuracy: 10.09\n",
      "[  30]  Training error: 0.90965 Training accuracy: 9.04 Test error: 0.91080  Test accuracy: 8.92\n",
      "[  31]  Training error: 0.89782 Training accuracy: 10.22 Test error: 0.89900  Test accuracy: 10.10\n",
      "[  32]  Training error: 0.90085 Training accuracy: 9.92 Test error: 0.89910  Test accuracy: 10.09\n",
      "[  33]  Training error: 0.90137 Training accuracy: 9.86 Test error: 0.90420  Test accuracy: 9.58\n",
      "[  34]  Training error: 0.90085 Training accuracy: 9.92 Test error: 0.89910  Test accuracy: 10.09\n",
      "[  35]  Training error: 0.90248 Training accuracy: 9.75 Test error: 0.90260  Test accuracy: 9.74\n",
      "[  36]  Training error: 0.89558 Training accuracy: 10.44 Test error: 0.89720  Test accuracy: 10.28\n",
      "[  37]  Training error: 0.89782 Training accuracy: 10.22 Test error: 0.89900  Test accuracy: 10.10\n",
      "[  38]  Training error: 0.90263 Training accuracy: 9.74 Test error: 0.90180  Test accuracy: 9.82\n",
      "[  39]  Training error: 0.90248 Training accuracy: 9.75 Test error: 0.90260  Test accuracy: 9.74\n",
      "[  40]  Training error: 0.90085 Training accuracy: 9.92 Test error: 0.89910  Test accuracy: 10.09\n",
      "[  41]  Training error: 0.90263 Training accuracy: 9.74 Test error: 0.90180  Test accuracy: 9.82\n",
      "[  42]  Training error: 0.88763 Training accuracy: 11.24 Test error: 0.88650  Test accuracy: 11.35\n",
      "[  43]  Training error: 0.90085 Training accuracy: 9.92 Test error: 0.89910  Test accuracy: 10.09\n",
      "[  44]  Training error: 0.90085 Training accuracy: 9.92 Test error: 0.89910  Test accuracy: 10.09\n",
      "[  45]  Training error: 0.90248 Training accuracy: 9.75 Test error: 0.90260  Test accuracy: 9.74\n",
      "[  46]  Training error: 0.90248 Training accuracy: 9.75 Test error: 0.90260  Test accuracy: 9.74\n",
      "[  47]  Training error: 0.90263 Training accuracy: 9.74 Test error: 0.90180  Test accuracy: 9.82\n",
      "[  48]  Training error: 0.90085 Training accuracy: 9.92 Test error: 0.89910  Test accuracy: 10.09\n",
      "[  49]  Training error: 0.90137 Training accuracy: 9.86 Test error: 0.90420  Test accuracy: 9.58\n",
      "[  50]  Training error: 0.90248 Training accuracy: 9.75 Test error: 0.90260  Test accuracy: 9.74\n",
      "[  51]  Training error: 0.90263 Training accuracy: 9.74 Test error: 0.90180  Test accuracy: 9.82\n",
      "[  52]  Training error: 0.89558 Training accuracy: 10.44 Test error: 0.89720  Test accuracy: 10.28\n",
      "[  53]  Training error: 0.89782 Training accuracy: 10.22 Test error: 0.89900  Test accuracy: 10.10\n",
      "[  54]  Training error: 0.90070 Training accuracy: 9.93 Test error: 0.89680  Test accuracy: 10.32\n",
      "[  55]  Training error: 0.90085 Training accuracy: 9.92 Test error: 0.89910  Test accuracy: 10.09\n",
      "[  56]  Training error: 0.90137 Training accuracy: 9.86 Test error: 0.90420  Test accuracy: 9.58\n",
      "[  57]  Training error: 0.89782 Training accuracy: 10.22 Test error: 0.89900  Test accuracy: 10.10\n",
      "[  58]  Training error: 0.90085 Training accuracy: 9.92 Test error: 0.89910  Test accuracy: 10.09\n",
      "[  59]  Training error: 0.90085 Training accuracy: 9.92 Test error: 0.89910  Test accuracy: 10.09\n",
      "[  60]  Training error: 0.90248 Training accuracy: 9.75 Test error: 0.90260  Test accuracy: 9.74\n",
      "[  61]  Training error: 0.89558 Training accuracy: 10.44 Test error: 0.89720  Test accuracy: 10.28\n",
      "[  62]  Training error: 0.90248 Training accuracy: 9.75 Test error: 0.90260  Test accuracy: 9.74\n",
      "[  63]  Training error: 0.90128 Training accuracy: 9.87 Test error: 0.90200  Test accuracy: 9.80\n",
      "[  64]  Training error: 0.90248 Training accuracy: 9.75 Test error: 0.90260  Test accuracy: 9.74\n",
      "[  65]  Training error: 0.90263 Training accuracy: 9.74 Test error: 0.90180  Test accuracy: 9.82\n",
      "[  66]  Training error: 0.90137 Training accuracy: 9.86 Test error: 0.90420  Test accuracy: 9.58\n",
      "[  67]  Training error: 0.90070 Training accuracy: 9.93 Test error: 0.89680  Test accuracy: 10.32\n",
      "[  68]  Training error: 0.90085 Training accuracy: 9.92 Test error: 0.89910  Test accuracy: 10.09\n",
      "[  69]  Training error: 0.90248 Training accuracy: 9.75 Test error: 0.90260  Test accuracy: 9.74\n",
      "Done:)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size=100;\n",
    "\n",
    "train_data, train_labels, valid_data, valid_labels=prepare_for_backprop(batch_size, Xtr, Ltr, X_test, L_test)\n",
    "\n",
    "mlp = MultiLayerPerceptron(layer_config=[784, 100, 100, 10], batch_size=batch_size)\n",
    "\n",
    "mlp.evaluate(train_data, train_labels, valid_data, valid_labels,\n",
    "             eval_train=True,eta=0.5)\n",
    "\n",
    "print(\"Done:)\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with ReLU as output function in hidden layers and default configuration: number of epochs = 70 and learning rate =0.05\n",
    "\n",
    "\n",
    "- Results at last epoch -  Training error: 0.90137 Training accuracy: 9.86 Test error: 0.90420  Test accuracy: 9.58\n",
    "- Error and accuracy remains same from first epoch to last epoch.\n",
    "- Model doesnot converge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating data...\n",
      "Batch size 100, the number of examples 60000.\n",
      "Batch size 100, the number of examples 10000.\n",
      "Done!\n",
      "Initializing input layer with size 784.\n",
      "Initializing hidden layer with size 100.\n",
      "Initializing hidden layer with size 100.\n",
      "Initializing output layer with size 10.\n",
      "Done!\n",
      "Training for 70 epochs...\n",
      "[   0]  Training error: 0.90137 Training accuracy: 9.86 Test error: 0.90420  Test accuracy: 9.58\n",
      "[   1]  Training error: 0.90137 Training accuracy: 9.86 Test error: 0.90420  Test accuracy: 9.58\n",
      "[   2]  Training error: 0.90137 Training accuracy: 9.86 Test error: 0.90420  Test accuracy: 9.58\n",
      "[   3]  Training error: 0.90137 Training accuracy: 9.86 Test error: 0.90420  Test accuracy: 9.58\n",
      "[   4]  Training error: 0.90137 Training accuracy: 9.86 Test error: 0.90420  Test accuracy: 9.58\n",
      "[   5]  Training error: 0.90137 Training accuracy: 9.86 Test error: 0.90420  Test accuracy: 9.58\n",
      "[   6]  Training error: 0.90137 Training accuracy: 9.86 Test error: 0.90420  Test accuracy: 9.58\n",
      "[   7]  Training error: 0.90137 Training accuracy: 9.86 Test error: 0.90420  Test accuracy: 9.58\n",
      "[   8]  Training error: 0.90137 Training accuracy: 9.86 Test error: 0.90420  Test accuracy: 9.58\n",
      "[   9]  Training error: 0.90137 Training accuracy: 9.86 Test error: 0.90420  Test accuracy: 9.58\n",
      "[  10]  Training error: 0.90137 Training accuracy: 9.86 Test error: 0.90420  Test accuracy: 9.58\n",
      "[  11]  Training error: 0.90137 Training accuracy: 9.86 Test error: 0.90420  Test accuracy: 9.58\n",
      "[  12]  Training error: 0.90137 Training accuracy: 9.86 Test error: 0.90420  Test accuracy: 9.58\n",
      "[  13]  Training error: 0.90137 Training accuracy: 9.86 Test error: 0.90420  Test accuracy: 9.58\n",
      "[  14]  Training error: 0.90137 Training accuracy: 9.86 Test error: 0.90420  Test accuracy: 9.58\n",
      "[  15]  Training error: 0.90137 Training accuracy: 9.86 Test error: 0.90420  Test accuracy: 9.58\n",
      "[  16]  Training error: 0.90137 Training accuracy: 9.86 Test error: 0.90420  Test accuracy: 9.58\n",
      "[  17]  Training error: 0.90137 Training accuracy: 9.86 Test error: 0.90420  Test accuracy: 9.58\n",
      "[  18]  Training error: 0.90137 Training accuracy: 9.86 Test error: 0.90420  Test accuracy: 9.58\n",
      "[  19]  Training error: 0.90137 Training accuracy: 9.86 Test error: 0.90420  Test accuracy: 9.58\n",
      "[  20]  Training error: 0.90137 Training accuracy: 9.86 Test error: 0.90420  Test accuracy: 9.58\n",
      "[  21]  Training error: 0.90137 Training accuracy: 9.86 Test error: 0.90420  Test accuracy: 9.58\n",
      "[  22]  Training error: 0.90137 Training accuracy: 9.86 Test error: 0.90420  Test accuracy: 9.58\n",
      "[  23]  Training error: 0.90137 Training accuracy: 9.86 Test error: 0.90420  Test accuracy: 9.58\n",
      "[  24]  Training error: 0.90137 Training accuracy: 9.86 Test error: 0.90420  Test accuracy: 9.58\n",
      "[  25]  Training error: 0.90137 Training accuracy: 9.86 Test error: 0.90420  Test accuracy: 9.58\n",
      "[  26]  Training error: 0.90137 Training accuracy: 9.86 Test error: 0.90420  Test accuracy: 9.58\n",
      "[  27]  Training error: 0.90137 Training accuracy: 9.86 Test error: 0.90420  Test accuracy: 9.58\n",
      "[  28]  Training error: 0.90137 Training accuracy: 9.86 Test error: 0.90420  Test accuracy: 9.58\n",
      "[  29]  Training error: 0.90137 Training accuracy: 9.86 Test error: 0.90420  Test accuracy: 9.58\n",
      "[  30]  Training error: 0.90137 Training accuracy: 9.86 Test error: 0.90420  Test accuracy: 9.58\n",
      "[  31]  Training error: 0.90137 Training accuracy: 9.86 Test error: 0.90420  Test accuracy: 9.58\n",
      "[  32]  Training error: 0.90137 Training accuracy: 9.86 Test error: 0.90420  Test accuracy: 9.58\n",
      "[  33]  Training error: 0.90137 Training accuracy: 9.86 Test error: 0.90420  Test accuracy: 9.58\n",
      "[  34]  Training error: 0.90137 Training accuracy: 9.86 Test error: 0.90420  Test accuracy: 9.58\n",
      "[  35]  Training error: 0.90137 Training accuracy: 9.86 Test error: 0.90420  Test accuracy: 9.58\n",
      "[  36]  Training error: 0.90137 Training accuracy: 9.86 Test error: 0.90420  Test accuracy: 9.58\n",
      "[  37]  Training error: 0.90137 Training accuracy: 9.86 Test error: 0.90420  Test accuracy: 9.58\n",
      "[  38]  Training error: 0.90137 Training accuracy: 9.86 Test error: 0.90420  Test accuracy: 9.58\n",
      "[  39]  Training error: 0.90137 Training accuracy: 9.86 Test error: 0.90420  Test accuracy: 9.58\n",
      "[  40]  Training error: 0.90137 Training accuracy: 9.86 Test error: 0.90420  Test accuracy: 9.58\n",
      "[  41]  Training error: 0.90137 Training accuracy: 9.86 Test error: 0.90420  Test accuracy: 9.58\n",
      "[  42]  Training error: 0.90137 Training accuracy: 9.86 Test error: 0.90420  Test accuracy: 9.58\n",
      "[  43]  Training error: 0.90137 Training accuracy: 9.86 Test error: 0.90420  Test accuracy: 9.58\n",
      "[  44]  Training error: 0.90137 Training accuracy: 9.86 Test error: 0.90420  Test accuracy: 9.58\n",
      "[  45]  Training error: 0.90137 Training accuracy: 9.86 Test error: 0.90420  Test accuracy: 9.58\n",
      "[  46]  Training error: 0.90137 Training accuracy: 9.86 Test error: 0.90420  Test accuracy: 9.58\n",
      "[  47]  Training error: 0.90137 Training accuracy: 9.86 Test error: 0.90420  Test accuracy: 9.58\n",
      "[  48]  Training error: 0.90137 Training accuracy: 9.86 Test error: 0.90420  Test accuracy: 9.58\n",
      "[  49]  Training error: 0.90137 Training accuracy: 9.86 Test error: 0.90420  Test accuracy: 9.58\n",
      "[  50]  Training error: 0.90137 Training accuracy: 9.86 Test error: 0.90420  Test accuracy: 9.58\n",
      "[  51]  Training error: 0.90137 Training accuracy: 9.86 Test error: 0.90420  Test accuracy: 9.58\n",
      "[  52]  Training error: 0.90137 Training accuracy: 9.86 Test error: 0.90420  Test accuracy: 9.58\n",
      "[  53]  Training error: 0.90137 Training accuracy: 9.86 Test error: 0.90420  Test accuracy: 9.58\n",
      "[  54]  Training error: 0.90137 Training accuracy: 9.86 Test error: 0.90420  Test accuracy: 9.58\n",
      "[  55]  Training error: 0.90137 Training accuracy: 9.86 Test error: 0.90420  Test accuracy: 9.58\n",
      "[  56]  Training error: 0.90137 Training accuracy: 9.86 Test error: 0.90420  Test accuracy: 9.58\n",
      "[  57]  Training error: 0.90137 Training accuracy: 9.86 Test error: 0.90420  Test accuracy: 9.58\n",
      "[  58]  Training error: 0.90137 Training accuracy: 9.86 Test error: 0.90420  Test accuracy: 9.58\n",
      "[  59]  Training error: 0.90137 Training accuracy: 9.86 Test error: 0.90420  Test accuracy: 9.58\n",
      "[  60]  Training error: 0.90137 Training accuracy: 9.86 Test error: 0.90420  Test accuracy: 9.58\n",
      "[  61]  Training error: 0.90137 Training accuracy: 9.86 Test error: 0.90420  Test accuracy: 9.58\n",
      "[  62]  Training error: 0.90137 Training accuracy: 9.86 Test error: 0.90420  Test accuracy: 9.58\n",
      "[  63]  Training error: 0.90137 Training accuracy: 9.86 Test error: 0.90420  Test accuracy: 9.58\n",
      "[  64]  Training error: 0.90137 Training accuracy: 9.86 Test error: 0.90420  Test accuracy: 9.58\n",
      "[  65]  Training error: 0.90137 Training accuracy: 9.86 Test error: 0.90420  Test accuracy: 9.58\n",
      "[  66]  Training error: 0.90137 Training accuracy: 9.86 Test error: 0.90420  Test accuracy: 9.58\n",
      "[  67]  Training error: 0.90137 Training accuracy: 9.86 Test error: 0.90420  Test accuracy: 9.58\n",
      "[  68]  Training error: 0.90137 Training accuracy: 9.86 Test error: 0.90420  Test accuracy: 9.58\n",
      "[  69]  Training error: 0.90137 Training accuracy: 9.86 Test error: 0.90420  Test accuracy: 9.58\n",
      "Done:)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size=100;\n",
    "\n",
    "train_data, train_labels, valid_data, valid_labels=prepare_for_backprop(batch_size, Xtr, Ltr, X_test, L_test)\n",
    "\n",
    "mlp = MultiLayerPerceptron(layer_config=[784, 100, 100, 10], batch_size=batch_size, activation_hidden = f_relu)\n",
    "\n",
    "mlp.evaluate(train_data, train_labels, valid_data, valid_labels,\n",
    "             eval_train=True,eta=0.05)\n",
    "\n",
    "print(\"Done:)\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with ReLU as output function in hidden layers and configuration: number of epochs = 70 and learning rate =0.005\n",
    "\n",
    " \n",
    "- Results ate final epoch -  Training error: 0.00002 Training accuracy: 100.00 Test error: 0.02030  Test accuracy: 97.97\n",
    "- With ReLU as ouput function and Learning rate 0.005, we achieve same accuracy as we get with sigmoid output function with learning rate 0.05\n",
    "- Convergence starts bit earlier at 19 epoch as compared to 51 epoch when learning rate of 0.001 was used (see below for tests with lr 0.001)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating data...\n",
      "Batch size 100, the number of examples 60000.\n",
      "Batch size 100, the number of examples 10000.\n",
      "Done!\n",
      "Initializing input layer with size 784.\n",
      "Initializing hidden layer with size 100.\n",
      "Initializing hidden layer with size 100.\n",
      "Initializing output layer with size 10.\n",
      "Done!\n",
      "Training for 70 epochs...\n",
      "[   0]  Training error: 0.89558 Training accuracy: 10.44 Test error: 0.89720  Test accuracy: 10.28\n",
      "[   1]  Training error: 0.89558 Training accuracy: 10.44 Test error: 0.89720  Test accuracy: 10.28\n",
      "[   2]  Training error: 0.89558 Training accuracy: 10.44 Test error: 0.89720  Test accuracy: 10.28\n",
      "[   3]  Training error: 0.89558 Training accuracy: 10.44 Test error: 0.89720  Test accuracy: 10.28\n",
      "[   4]  Training error: 0.89558 Training accuracy: 10.44 Test error: 0.89720  Test accuracy: 10.28\n",
      "[   5]  Training error: 0.89558 Training accuracy: 10.44 Test error: 0.89720  Test accuracy: 10.28\n",
      "[   6]  Training error: 0.89558 Training accuracy: 10.44 Test error: 0.89720  Test accuracy: 10.28\n",
      "[   7]  Training error: 0.89558 Training accuracy: 10.44 Test error: 0.89720  Test accuracy: 10.28\n",
      "[   8]  Training error: 0.89558 Training accuracy: 10.44 Test error: 0.89720  Test accuracy: 10.28\n",
      "[   9]  Training error: 0.89558 Training accuracy: 10.44 Test error: 0.89720  Test accuracy: 10.28\n",
      "[  10]  Training error: 0.89558 Training accuracy: 10.44 Test error: 0.89720  Test accuracy: 10.28\n",
      "[  11]  Training error: 0.89558 Training accuracy: 10.44 Test error: 0.89720  Test accuracy: 10.28\n",
      "[  12]  Training error: 0.89558 Training accuracy: 10.44 Test error: 0.89720  Test accuracy: 10.28\n",
      "[  13]  Training error: 0.89558 Training accuracy: 10.44 Test error: 0.89720  Test accuracy: 10.28\n",
      "[  14]  Training error: 0.89558 Training accuracy: 10.44 Test error: 0.89720  Test accuracy: 10.28\n",
      "[  15]  Training error: 0.89558 Training accuracy: 10.44 Test error: 0.89720  Test accuracy: 10.28\n",
      "[  16]  Training error: 0.89558 Training accuracy: 10.44 Test error: 0.89720  Test accuracy: 10.28\n",
      "[  17]  Training error: 0.89558 Training accuracy: 10.44 Test error: 0.89720  Test accuracy: 10.28\n",
      "[  18]  Training error: 0.89558 Training accuracy: 10.44 Test error: 0.89720  Test accuracy: 10.28\n",
      "[  19]  Training error: 0.64337 Training accuracy: 35.66 Test error: 0.64830  Test accuracy: 35.17\n",
      "[  20]  Training error: 0.09030 Training accuracy: 90.97 Test error: 0.09320  Test accuracy: 90.68\n",
      "[  21]  Training error: 0.07387 Training accuracy: 92.61 Test error: 0.07660  Test accuracy: 92.34\n",
      "[  22]  Training error: 0.04832 Training accuracy: 95.17 Test error: 0.05620  Test accuracy: 94.38\n",
      "[  23]  Training error: 0.03120 Training accuracy: 96.88 Test error: 0.03910  Test accuracy: 96.09\n",
      "[  24]  Training error: 0.02595 Training accuracy: 97.41 Test error: 0.03400  Test accuracy: 96.60\n",
      "[  25]  Training error: 0.02112 Training accuracy: 97.89 Test error: 0.03240  Test accuracy: 96.76\n",
      "[  26]  Training error: 0.02065 Training accuracy: 97.94 Test error: 0.03340  Test accuracy: 96.66\n",
      "[  27]  Training error: 0.01867 Training accuracy: 98.13 Test error: 0.03230  Test accuracy: 96.77\n",
      "[  28]  Training error: 0.02530 Training accuracy: 97.47 Test error: 0.03840  Test accuracy: 96.16\n",
      "[  29]  Training error: 0.01970 Training accuracy: 98.03 Test error: 0.03460  Test accuracy: 96.54\n",
      "[  30]  Training error: 0.02103 Training accuracy: 97.90 Test error: 0.03720  Test accuracy: 96.28\n",
      "[  31]  Training error: 0.01383 Training accuracy: 98.62 Test error: 0.02990  Test accuracy: 97.01\n",
      "[  32]  Training error: 0.01710 Training accuracy: 98.29 Test error: 0.03250  Test accuracy: 96.75\n",
      "[  33]  Training error: 0.02005 Training accuracy: 98.00 Test error: 0.03610  Test accuracy: 96.39\n",
      "[  34]  Training error: 0.01353 Training accuracy: 98.65 Test error: 0.03200  Test accuracy: 96.80\n",
      "[  35]  Training error: 0.00962 Training accuracy: 99.04 Test error: 0.02760  Test accuracy: 97.24\n",
      "[  36]  Training error: 0.01108 Training accuracy: 98.89 Test error: 0.02870  Test accuracy: 97.13\n",
      "[  37]  Training error: 0.00977 Training accuracy: 99.02 Test error: 0.03000  Test accuracy: 97.00\n",
      "[  38]  Training error: 0.00998 Training accuracy: 99.00 Test error: 0.02810  Test accuracy: 97.19\n",
      "[  39]  Training error: 0.01047 Training accuracy: 98.95 Test error: 0.03010  Test accuracy: 96.99\n",
      "[  40]  Training error: 0.00683 Training accuracy: 99.32 Test error: 0.02700  Test accuracy: 97.30\n",
      "[  41]  Training error: 0.02192 Training accuracy: 97.81 Test error: 0.04080  Test accuracy: 95.92\n",
      "[  42]  Training error: 0.01027 Training accuracy: 98.97 Test error: 0.02820  Test accuracy: 97.18\n",
      "[  43]  Training error: 0.01045 Training accuracy: 98.95 Test error: 0.03020  Test accuracy: 96.98\n",
      "[  44]  Training error: 0.00630 Training accuracy: 99.37 Test error: 0.02730  Test accuracy: 97.27\n",
      "[  45]  Training error: 0.00663 Training accuracy: 99.34 Test error: 0.02730  Test accuracy: 97.27\n",
      "[  46]  Training error: 0.00258 Training accuracy: 99.74 Test error: 0.02450  Test accuracy: 97.55\n",
      "[  47]  Training error: 0.00240 Training accuracy: 99.76 Test error: 0.02360  Test accuracy: 97.64\n",
      "[  48]  Training error: 0.00155 Training accuracy: 99.84 Test error: 0.02130  Test accuracy: 97.87\n",
      "[  49]  Training error: 0.00225 Training accuracy: 99.78 Test error: 0.02350  Test accuracy: 97.65\n",
      "[  50]  Training error: 0.00160 Training accuracy: 99.84 Test error: 0.02320  Test accuracy: 97.68\n",
      "[  51]  Training error: 0.00153 Training accuracy: 99.85 Test error: 0.02250  Test accuracy: 97.75\n",
      "[  52]  Training error: 0.00327 Training accuracy: 99.67 Test error: 0.02600  Test accuracy: 97.40\n",
      "[  53]  Training error: 0.00383 Training accuracy: 99.62 Test error: 0.02610  Test accuracy: 97.39\n",
      "[  54]  Training error: 0.00175 Training accuracy: 99.83 Test error: 0.02320  Test accuracy: 97.68\n",
      "[  55]  Training error: 0.00237 Training accuracy: 99.76 Test error: 0.02480  Test accuracy: 97.52\n",
      "[  56]  Training error: 0.00710 Training accuracy: 99.29 Test error: 0.02660  Test accuracy: 97.34\n",
      "[  57]  Training error: 0.00670 Training accuracy: 99.33 Test error: 0.02910  Test accuracy: 97.09\n",
      "[  58]  Training error: 0.00485 Training accuracy: 99.52 Test error: 0.02460  Test accuracy: 97.54\n",
      "[  59]  Training error: 0.00100 Training accuracy: 99.90 Test error: 0.02170  Test accuracy: 97.83\n",
      "[  60]  Training error: 0.00078 Training accuracy: 99.92 Test error: 0.02030  Test accuracy: 97.97\n",
      "[  61]  Training error: 0.00098 Training accuracy: 99.90 Test error: 0.02270  Test accuracy: 97.73\n",
      "[  62]  Training error: 0.00013 Training accuracy: 99.99 Test error: 0.02080  Test accuracy: 97.92\n",
      "[  63]  Training error: 0.00003 Training accuracy: 100.00 Test error: 0.02100  Test accuracy: 97.90\n",
      "[  64]  Training error: 0.00005 Training accuracy: 100.00 Test error: 0.02200  Test accuracy: 97.80\n",
      "[  65]  Training error: 0.00002 Training accuracy: 100.00 Test error: 0.02110  Test accuracy: 97.89\n",
      "[  66]  Training error: 0.00002 Training accuracy: 100.00 Test error: 0.02060  Test accuracy: 97.94\n",
      "[  67]  Training error: 0.00002 Training accuracy: 100.00 Test error: 0.02020  Test accuracy: 97.98\n",
      "[  68]  Training error: 0.00002 Training accuracy: 100.00 Test error: 0.02040  Test accuracy: 97.96\n",
      "[  69]  Training error: 0.00002 Training accuracy: 100.00 Test error: 0.02030  Test accuracy: 97.97\n",
      "Done:)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size=100;\n",
    "\n",
    "train_data, train_labels, valid_data, valid_labels=prepare_for_backprop(batch_size, Xtr, Ltr, X_test, L_test)\n",
    "\n",
    "mlp = MultiLayerPerceptron(layer_config=[784, 100, 100, 10], batch_size=batch_size, activation_hidden = f_relu)\n",
    "\n",
    "mlp.evaluate(train_data, train_labels, valid_data, valid_labels,\n",
    "             eval_train=True,eta=0.005)\n",
    "\n",
    "print(\"Done:)\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with ReLU as output function in hidden layers and configuration: number of epochs = 70 and learning rate =0.001\n",
    "\n",
    "\n",
    "- Results at final epoch -  Training error: 0.01837 Training accuracy: 98.16 Test error: 0.03580  Test accuracy: 96.42\n",
    "- Error and accuracy remains same uptil the 50th epoch\n",
    "- Only from 51 epochs loss started reducing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating data...\n",
      "Batch size 100, the number of examples 60000.\n",
      "Batch size 100, the number of examples 10000.\n",
      "Done!\n",
      "Initializing input layer with size 784.\n",
      "Initializing hidden layer with size 100.\n",
      "Initializing hidden layer with size 100.\n",
      "Initializing output layer with size 10.\n",
      "Done!\n",
      "Training for 70 epochs...\n",
      "[   0]  Training error: 0.88763 Training accuracy: 11.24 Test error: 0.88650  Test accuracy: 11.35\n",
      "[   1]  Training error: 0.88763 Training accuracy: 11.24 Test error: 0.88650  Test accuracy: 11.35\n",
      "[   2]  Training error: 0.88763 Training accuracy: 11.24 Test error: 0.88650  Test accuracy: 11.35\n",
      "[   3]  Training error: 0.88763 Training accuracy: 11.24 Test error: 0.88650  Test accuracy: 11.35\n",
      "[   4]  Training error: 0.88763 Training accuracy: 11.24 Test error: 0.88650  Test accuracy: 11.35\n",
      "[   5]  Training error: 0.88763 Training accuracy: 11.24 Test error: 0.88650  Test accuracy: 11.35\n",
      "[   6]  Training error: 0.88763 Training accuracy: 11.24 Test error: 0.88650  Test accuracy: 11.35\n",
      "[   7]  Training error: 0.88763 Training accuracy: 11.24 Test error: 0.88650  Test accuracy: 11.35\n",
      "[   8]  Training error: 0.88763 Training accuracy: 11.24 Test error: 0.88650  Test accuracy: 11.35\n",
      "[   9]  Training error: 0.88763 Training accuracy: 11.24 Test error: 0.88650  Test accuracy: 11.35\n",
      "[  10]  Training error: 0.88763 Training accuracy: 11.24 Test error: 0.88650  Test accuracy: 11.35\n",
      "[  11]  Training error: 0.88763 Training accuracy: 11.24 Test error: 0.88650  Test accuracy: 11.35\n",
      "[  12]  Training error: 0.88763 Training accuracy: 11.24 Test error: 0.88650  Test accuracy: 11.35\n",
      "[  13]  Training error: 0.88763 Training accuracy: 11.24 Test error: 0.88650  Test accuracy: 11.35\n",
      "[  14]  Training error: 0.88763 Training accuracy: 11.24 Test error: 0.88650  Test accuracy: 11.35\n",
      "[  15]  Training error: 0.88763 Training accuracy: 11.24 Test error: 0.88650  Test accuracy: 11.35\n",
      "[  16]  Training error: 0.88763 Training accuracy: 11.24 Test error: 0.88650  Test accuracy: 11.35\n",
      "[  17]  Training error: 0.88763 Training accuracy: 11.24 Test error: 0.88650  Test accuracy: 11.35\n",
      "[  18]  Training error: 0.88763 Training accuracy: 11.24 Test error: 0.88650  Test accuracy: 11.35\n",
      "[  19]  Training error: 0.88763 Training accuracy: 11.24 Test error: 0.88650  Test accuracy: 11.35\n",
      "[  20]  Training error: 0.88763 Training accuracy: 11.24 Test error: 0.88650  Test accuracy: 11.35\n",
      "[  21]  Training error: 0.88763 Training accuracy: 11.24 Test error: 0.88650  Test accuracy: 11.35\n",
      "[  22]  Training error: 0.88763 Training accuracy: 11.24 Test error: 0.88650  Test accuracy: 11.35\n",
      "[  23]  Training error: 0.88763 Training accuracy: 11.24 Test error: 0.88650  Test accuracy: 11.35\n",
      "[  24]  Training error: 0.88763 Training accuracy: 11.24 Test error: 0.88650  Test accuracy: 11.35\n",
      "[  25]  Training error: 0.88763 Training accuracy: 11.24 Test error: 0.88650  Test accuracy: 11.35\n",
      "[  26]  Training error: 0.88763 Training accuracy: 11.24 Test error: 0.88650  Test accuracy: 11.35\n",
      "[  27]  Training error: 0.88763 Training accuracy: 11.24 Test error: 0.88650  Test accuracy: 11.35\n",
      "[  28]  Training error: 0.88763 Training accuracy: 11.24 Test error: 0.88650  Test accuracy: 11.35\n",
      "[  29]  Training error: 0.88763 Training accuracy: 11.24 Test error: 0.88650  Test accuracy: 11.35\n",
      "[  30]  Training error: 0.88763 Training accuracy: 11.24 Test error: 0.88650  Test accuracy: 11.35\n",
      "[  31]  Training error: 0.88763 Training accuracy: 11.24 Test error: 0.88650  Test accuracy: 11.35\n",
      "[  32]  Training error: 0.88763 Training accuracy: 11.24 Test error: 0.88650  Test accuracy: 11.35\n",
      "[  33]  Training error: 0.88763 Training accuracy: 11.24 Test error: 0.88650  Test accuracy: 11.35\n",
      "[  34]  Training error: 0.88763 Training accuracy: 11.24 Test error: 0.88650  Test accuracy: 11.35\n",
      "[  35]  Training error: 0.88763 Training accuracy: 11.24 Test error: 0.88650  Test accuracy: 11.35\n",
      "[  36]  Training error: 0.88763 Training accuracy: 11.24 Test error: 0.88650  Test accuracy: 11.35\n",
      "[  37]  Training error: 0.88763 Training accuracy: 11.24 Test error: 0.88650  Test accuracy: 11.35\n",
      "[  38]  Training error: 0.88763 Training accuracy: 11.24 Test error: 0.88650  Test accuracy: 11.35\n",
      "[  39]  Training error: 0.88763 Training accuracy: 11.24 Test error: 0.88650  Test accuracy: 11.35\n",
      "[  40]  Training error: 0.88763 Training accuracy: 11.24 Test error: 0.88650  Test accuracy: 11.35\n",
      "[  41]  Training error: 0.88763 Training accuracy: 11.24 Test error: 0.88650  Test accuracy: 11.35\n",
      "[  42]  Training error: 0.88763 Training accuracy: 11.24 Test error: 0.88650  Test accuracy: 11.35\n",
      "[  43]  Training error: 0.88763 Training accuracy: 11.24 Test error: 0.88650  Test accuracy: 11.35\n",
      "[  44]  Training error: 0.88763 Training accuracy: 11.24 Test error: 0.88650  Test accuracy: 11.35\n",
      "[  45]  Training error: 0.88763 Training accuracy: 11.24 Test error: 0.88650  Test accuracy: 11.35\n",
      "[  46]  Training error: 0.88763 Training accuracy: 11.24 Test error: 0.88650  Test accuracy: 11.35\n",
      "[  47]  Training error: 0.88763 Training accuracy: 11.24 Test error: 0.88650  Test accuracy: 11.35\n",
      "[  48]  Training error: 0.88763 Training accuracy: 11.24 Test error: 0.88650  Test accuracy: 11.35\n",
      "[  49]  Training error: 0.88763 Training accuracy: 11.24 Test error: 0.88650  Test accuracy: 11.35\n",
      "[  50]  Training error: 0.88763 Training accuracy: 11.24 Test error: 0.88650  Test accuracy: 11.35\n",
      "[  51]  Training error: 0.79062 Training accuracy: 20.94 Test error: 0.78860  Test accuracy: 21.14\n",
      "[  52]  Training error: 0.47905 Training accuracy: 52.09 Test error: 0.48880  Test accuracy: 51.12\n",
      "[  53]  Training error: 0.18310 Training accuracy: 81.69 Test error: 0.18210  Test accuracy: 81.79\n",
      "[  54]  Training error: 0.11225 Training accuracy: 88.78 Test error: 0.11390  Test accuracy: 88.61\n",
      "[  55]  Training error: 0.08000 Training accuracy: 92.00 Test error: 0.08420  Test accuracy: 91.58\n",
      "[  56]  Training error: 0.06572 Training accuracy: 93.43 Test error: 0.06960  Test accuracy: 93.04\n",
      "[  57]  Training error: 0.05642 Training accuracy: 94.36 Test error: 0.06230  Test accuracy: 93.77\n",
      "[  58]  Training error: 0.04813 Training accuracy: 95.19 Test error: 0.05410  Test accuracy: 94.59\n",
      "[  59]  Training error: 0.04223 Training accuracy: 95.78 Test error: 0.04950  Test accuracy: 95.05\n",
      "[  60]  Training error: 0.03713 Training accuracy: 96.29 Test error: 0.04560  Test accuracy: 95.44\n",
      "[  61]  Training error: 0.03357 Training accuracy: 96.64 Test error: 0.04390  Test accuracy: 95.61\n",
      "[  62]  Training error: 0.03013 Training accuracy: 96.99 Test error: 0.04040  Test accuracy: 95.96\n",
      "[  63]  Training error: 0.02663 Training accuracy: 97.34 Test error: 0.03850  Test accuracy: 96.15\n",
      "[  64]  Training error: 0.02473 Training accuracy: 97.53 Test error: 0.03800  Test accuracy: 96.20\n",
      "[  65]  Training error: 0.02242 Training accuracy: 97.76 Test error: 0.03640  Test accuracy: 96.36\n",
      "[  66]  Training error: 0.02053 Training accuracy: 97.95 Test error: 0.03510  Test accuracy: 96.49\n",
      "[  67]  Training error: 0.01963 Training accuracy: 98.04 Test error: 0.03500  Test accuracy: 96.50\n",
      "[  68]  Training error: 0.01902 Training accuracy: 98.10 Test error: 0.03520  Test accuracy: 96.48\n",
      "[  69]  Training error: 0.01837 Training accuracy: 98.16 Test error: 0.03580  Test accuracy: 96.42\n",
      "Done:)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size=100;\n",
    "\n",
    "train_data, train_labels, valid_data, valid_labels=prepare_for_backprop(batch_size, Xtr, Ltr, X_test, L_test)\n",
    "\n",
    "mlp = MultiLayerPerceptron(layer_config=[784, 100, 100, 10], batch_size=batch_size, activation_hidden = f_relu)\n",
    "\n",
    "mlp.evaluate(train_data, train_labels, valid_data, valid_labels,\n",
    "             eval_train=True,eta=0.001)\n",
    "\n",
    "print(\"Done:)\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
